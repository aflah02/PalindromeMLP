{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "\n",
    "def read_text(file):\n",
    "    with open(file, 'r') as f:\n",
    "        text = f.readlines()\n",
    "    for i in range(len(text)):\n",
    "        text[i] = text[i].replace('\\n', '')\n",
    "    return text\n",
    "\n",
    "palindromic_strings = read_text(data_dir + 'palindromic_strings.txt')\n",
    "nonpalindromic_strings = read_text(data_dir + 'nonpalindromic_strings.txt')\n",
    "palindromic_strings_off_by_one_swap = read_text(data_dir + 'palindromic_strings_off_by_one_swap.txt')\n",
    "palindromic_strings_off_by_one_random_replacement = read_text(data_dir + 'palindromic_strings_off_by_one_random_replacement.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 4000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [40000, 4000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Desktop\\PalindromeMLP\\main.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/PalindromeMLP/main.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(dataset), \u001b[39mlen\u001b[39m(labels))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/PalindromeMLP/main.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# train test split\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Desktop/PalindromeMLP/main.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m train_dataset, test_dataset, train_labels, test_labels \u001b[39m=\u001b[39m train_test_split(dataset, labels, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m, stratify\u001b[39m=\u001b[39;49mlabels)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2614\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2611\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2612\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2614\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[0;32m   2616\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m   2617\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2618\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[0;32m   2619\u001b[0m )\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\sklearn\\utils\\validation.py:455\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \n\u001b[0;32m    438\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 455\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    456\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [40000, 4000]"
     ]
    }
   ],
   "source": [
    "challenge_dataset = palindromic_strings[-3000:] + nonpalindromic_strings[-1000:] + palindromic_strings_off_by_one_swap[-1000:] + palindromic_strings_off_by_one_random_replacement[-1000:]\n",
    "challenge_labels = [0] * 3000 + [1] * 1000 + [1] * 1000 + [1] * 1000\n",
    "challenge_finegrained_labels = {}\n",
    "for i in range(3000):\n",
    "    challenge_finegrained_labels[palindromic_strings[-3000:][i]] = 0\n",
    "for i in range(1000):\n",
    "    challenge_finegrained_labels[nonpalindromic_strings[-1000:][i]] = 1\n",
    "    challenge_finegrained_labels[palindromic_strings_off_by_one_swap[-1000:][i]] = 2\n",
    "    challenge_finegrained_labels[palindromic_strings_off_by_one_random_replacement[-1000:][i]] = 3\n",
    "\n",
    "dataset = palindromic_strings[:30000] + nonpalindromic_strings[:10000] + palindromic_strings_off_by_one_swap[:10000] + palindromic_strings_off_by_one_random_replacement[:10000]\n",
    "labels = [0] * 30000 + [1] * 10000 + [1] * 10000 + [1] * 10000\n",
    "finegrained_labels = {}\n",
    "for i in range(30000):\n",
    "    finegrained_labels[palindromic_strings[:30000][i]] = 0\n",
    "for i in range(10000):\n",
    "    finegrained_labels[nonpalindromic_strings[:10000][i]] = 1\n",
    "    finegrained_labels[palindromic_strings_off_by_one_swap[:10000][i]] = 2\n",
    "    finegrained_labels[palindromic_strings_off_by_one_random_replacement[:10000][i]] = 3\n",
    "print(len(dataset), len(labels))\n",
    "# train test split\n",
    "train_dataset, test_dataset, train_labels, test_labels = train_test_split(dataset, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'finegrained_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Desktop\\PalindromeMLP\\main.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/PalindromeMLP/main.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_dataset_finegrained_labels \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/PalindromeMLP/main.ipynb#X56sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m train_dataset:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Desktop/PalindromeMLP/main.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     train_dataset_finegrained_labels\u001b[39m.\u001b[39mappend(finegrained_labels[i])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/PalindromeMLP/main.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_dataset_finegrained_labels \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/PalindromeMLP/main.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m test_dataset:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'finegrained_labels' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset_finegrained_labels = []\n",
    "for i in train_dataset:\n",
    "    train_dataset_finegrained_labels.append(finegrained_labels[i])\n",
    "test_dataset_finegrained_labels = []\n",
    "for i in test_dataset:\n",
    "    test_dataset_finegrained_labels.append(finegrained_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 9\n",
    "all_chars = string.ascii_uppercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Using Alphabet Arrays With Bools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(seq):\n",
    "    seq = seq.upper()\n",
    "    assert len(seq) == SEQ_LENGTH, \"length of sequence must be {}\".format(SEQ_LENGTH)\n",
    "    encoding = [0]*len(all_chars)\n",
    "    for i, char in enumerate(seq):\n",
    "        encoding[all_chars.index(char)] = 1\n",
    "    return encoding\n",
    "\n",
    "encoded_train_dataset = [encode(seq) for seq in train_dataset]\n",
    "encoded_test_dataset = [encode(seq) for seq in test_dataset]\n",
    "encoded_challenge_dataset = [encode(seq) for seq in challenge_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.87485018\n",
      "Validation score: 0.500000\n",
      "Iteration 2, loss = 0.77278844\n",
      "Validation score: 0.500000\n",
      "Iteration 3, loss = 0.71823541\n",
      "Validation score: 0.501250\n",
      "Iteration 4, loss = 0.67151861\n",
      "Validation score: 0.648750\n",
      "Iteration 5, loss = 0.63646036\n",
      "Validation score: 0.755000\n",
      "Iteration 6, loss = 0.61691422\n",
      "Validation score: 0.711250\n",
      "Iteration 7, loss = 0.60566679\n",
      "Validation score: 0.700000\n",
      "Iteration 8, loss = 0.59577298\n",
      "Validation score: 0.706250\n",
      "Iteration 9, loss = 0.58535367\n",
      "Validation score: 0.717500\n",
      "Iteration 10, loss = 0.57381297\n",
      "Validation score: 0.737500\n",
      "Iteration 11, loss = 0.56105056\n",
      "Validation score: 0.765000\n",
      "Iteration 12, loss = 0.54675995\n",
      "Validation score: 0.783750\n",
      "Iteration 13, loss = 0.53130545\n",
      "Validation score: 0.820000\n",
      "Iteration 14, loss = 0.51364311\n",
      "Validation score: 0.851250\n",
      "Iteration 15, loss = 0.49418075\n",
      "Validation score: 0.862500\n",
      "Iteration 16, loss = 0.47307181\n",
      "Validation score: 0.883750\n",
      "Iteration 17, loss = 0.45029444\n",
      "Validation score: 0.908750\n",
      "Iteration 18, loss = 0.42598390\n",
      "Validation score: 0.922500\n",
      "Iteration 19, loss = 0.40079555\n",
      "Validation score: 0.943750\n",
      "Iteration 20, loss = 0.37528896\n",
      "Validation score: 0.958750\n",
      "Iteration 21, loss = 0.34990185\n",
      "Validation score: 0.963750\n",
      "Iteration 22, loss = 0.32530811\n",
      "Validation score: 0.967500\n",
      "Iteration 23, loss = 0.30162722\n",
      "Validation score: 0.970000\n",
      "Iteration 24, loss = 0.27934287\n",
      "Validation score: 0.971250\n",
      "Iteration 25, loss = 0.25861224\n",
      "Validation score: 0.971250\n",
      "Iteration 26, loss = 0.23933490\n",
      "Validation score: 0.975000\n",
      "Iteration 27, loss = 0.22179885\n",
      "Validation score: 0.973750\n",
      "Iteration 28, loss = 0.20576465\n",
      "Validation score: 0.976250\n",
      "Iteration 29, loss = 0.19142223\n",
      "Validation score: 0.976250\n",
      "Iteration 30, loss = 0.17866532\n",
      "Validation score: 0.976250\n",
      "Iteration 31, loss = 0.16725106\n",
      "Validation score: 0.978750\n",
      "Iteration 32, loss = 0.15694905\n",
      "Validation score: 0.977500\n",
      "Iteration 33, loss = 0.14785699\n",
      "Validation score: 0.971250\n",
      "Iteration 34, loss = 0.13980857\n",
      "Validation score: 0.976250\n",
      "Iteration 35, loss = 0.13219258\n",
      "Validation score: 0.981250\n",
      "Iteration 36, loss = 0.12541763\n",
      "Validation score: 0.981250\n",
      "Iteration 37, loss = 0.11967095\n",
      "Validation score: 0.982500\n",
      "Iteration 38, loss = 0.11432481\n",
      "Validation score: 0.983750\n",
      "Iteration 39, loss = 0.10907850\n",
      "Validation score: 0.985000\n",
      "Iteration 40, loss = 0.10445078\n",
      "Validation score: 0.988750\n",
      "Iteration 41, loss = 0.10053390\n",
      "Validation score: 0.986250\n",
      "Iteration 42, loss = 0.09666795\n",
      "Validation score: 0.987500\n",
      "Iteration 43, loss = 0.09334143\n",
      "Validation score: 0.985000\n",
      "Iteration 44, loss = 0.08986242\n",
      "Validation score: 0.986250\n",
      "Iteration 45, loss = 0.08680279\n",
      "Validation score: 0.987500\n",
      "Iteration 46, loss = 0.08405289\n",
      "Validation score: 0.990000\n",
      "Iteration 47, loss = 0.08144488\n",
      "Validation score: 0.988750\n",
      "Iteration 48, loss = 0.07897665\n",
      "Validation score: 0.988750\n",
      "Iteration 49, loss = 0.07676022\n",
      "Validation score: 0.990000\n",
      "Iteration 50, loss = 0.07467369\n",
      "Validation score: 0.988750\n",
      "Iteration 51, loss = 0.07283596\n",
      "Validation score: 0.990000\n",
      "Iteration 52, loss = 0.07091405\n",
      "Validation score: 0.990000\n",
      "Iteration 53, loss = 0.06910824\n",
      "Validation score: 0.991250\n",
      "Iteration 54, loss = 0.06749960\n",
      "Validation score: 0.991250\n",
      "Iteration 55, loss = 0.06592418\n",
      "Validation score: 0.991250\n",
      "Iteration 56, loss = 0.06445226\n",
      "Validation score: 0.991250\n",
      "Iteration 57, loss = 0.06302900\n",
      "Validation score: 0.991250\n",
      "Iteration 58, loss = 0.06174360\n",
      "Validation score: 0.991250\n",
      "Iteration 59, loss = 0.06059741\n",
      "Validation score: 0.991250\n",
      "Iteration 60, loss = 0.05944051\n",
      "Validation score: 0.991250\n",
      "Iteration 61, loss = 0.05828275\n",
      "Validation score: 0.992500\n",
      "Iteration 62, loss = 0.05721284\n",
      "Validation score: 0.991250\n",
      "Iteration 63, loss = 0.05622790\n",
      "Validation score: 0.991250\n",
      "Iteration 64, loss = 0.05524503\n",
      "Validation score: 0.992500\n",
      "Iteration 65, loss = 0.05416916\n",
      "Validation score: 0.991250\n",
      "Iteration 66, loss = 0.05329830\n",
      "Validation score: 0.995000\n",
      "Iteration 67, loss = 0.05246941\n",
      "Validation score: 0.993750\n",
      "Iteration 68, loss = 0.05163696\n",
      "Validation score: 0.993750\n",
      "Iteration 69, loss = 0.05083375\n",
      "Validation score: 0.995000\n",
      "Iteration 70, loss = 0.05013875\n",
      "Validation score: 0.995000\n",
      "Iteration 71, loss = 0.04950766\n",
      "Validation score: 0.995000\n",
      "Iteration 72, loss = 0.04862014\n",
      "Validation score: 0.993750\n",
      "Iteration 73, loss = 0.04812504\n",
      "Validation score: 0.995000\n",
      "Iteration 74, loss = 0.04729528\n",
      "Validation score: 0.995000\n",
      "Iteration 75, loss = 0.04668254\n",
      "Validation score: 0.995000\n",
      "Iteration 76, loss = 0.04606754\n",
      "Validation score: 0.995000\n",
      "Iteration 77, loss = 0.04551850\n",
      "Validation score: 0.995000\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=10, max_iter=1000,\n",
       "              random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=10, max_iter=1000,\n",
       "              random_state=42, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=10, max_iter=1000,\n",
       "              random_state=42, verbose=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(10), random_state=42, max_iter=1000, verbose=True, early_stopping=True, validation_fraction=0.1)\n",
    "clf.fit(encoded_train_dataset, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 1.0,\n",
       "  'recall': 0.987,\n",
       "  'f1-score': 0.9934574735782586,\n",
       "  'support': 1000.0},\n",
       " '1': {'precision': 0.9871668311944719,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9935419771485345,\n",
       "  'support': 1000.0},\n",
       " 'accuracy': 0.9935,\n",
       " 'macro avg': {'precision': 0.993583415597236,\n",
       "  'recall': 0.9935,\n",
       "  'f1-score': 0.9934997253633966,\n",
       "  'support': 2000.0},\n",
       " 'weighted avg': {'precision': 0.993583415597236,\n",
       "  'recall': 0.9935,\n",
       "  'f1-score': 0.9934997253633966,\n",
       "  'support': 2000.0}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = clf.predict(encoded_test_dataset)\n",
    "test_preds = classification_report(test_labels, test_preds, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 9995.0},\n",
       " '1': {'precision': 0.5001250312578145,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.6667777962993833,\n",
       "  'support': 10000.0},\n",
       " 'accuracy': 0.5001250312578145,\n",
       " 'macro avg': {'precision': 0.25006251562890724,\n",
       "  'recall': 0.5,\n",
       "  'f1-score': 0.33338889814969164,\n",
       "  'support': 19995.0},\n",
       " 'weighted avg': {'precision': 0.2501250468906299,\n",
       "  'recall': 0.5001250312578145,\n",
       "  'f1-score': 0.3334722662162457,\n",
       "  'support': 19995.0}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenge_preds = clf.predict(encoded_challenge_dataset)\n",
    "classification_report(challenge_labels, challenge_preds, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Using Alphabet Arrays With Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_with_freq(seq):\n",
    "    seq = seq.upper()\n",
    "    assert len(seq) == SEQ_LENGTH, \"length of sequence must be {}\".format(SEQ_LENGTH)\n",
    "    encoding = [0]*len(all_chars)\n",
    "    for i, char in enumerate(seq):\n",
    "        encoding[all_chars.index(char)] += 1\n",
    "    return encoding\n",
    "\n",
    "encoded_with_freq_train_dataset = [encode_with_freq(seq) for seq in train_dataset]\n",
    "encoded_with_freq_test_dataset = [encode_with_freq(seq) for seq in test_dataset]\n",
    "encoded_with_freq_challenge_dataset = [encode_with_freq(seq) for seq in challenge_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68582820\n",
      "Validation score: 0.642500\n",
      "Iteration 2, loss = 0.62864313\n",
      "Validation score: 0.760000\n",
      "Iteration 3, loss = 0.58608849\n",
      "Validation score: 0.805000\n",
      "Iteration 4, loss = 0.54995146\n",
      "Validation score: 0.830000\n",
      "Iteration 5, loss = 0.51820774\n",
      "Validation score: 0.843750\n",
      "Iteration 6, loss = 0.48938777\n",
      "Validation score: 0.853750\n",
      "Iteration 7, loss = 0.46366243\n",
      "Validation score: 0.860000\n",
      "Iteration 8, loss = 0.44009541\n",
      "Validation score: 0.871250\n",
      "Iteration 9, loss = 0.41659527\n",
      "Validation score: 0.871250\n",
      "Iteration 10, loss = 0.39573664\n",
      "Validation score: 0.882500\n",
      "Iteration 11, loss = 0.37645661\n",
      "Validation score: 0.881250\n",
      "Iteration 12, loss = 0.35831642\n",
      "Validation score: 0.892500\n",
      "Iteration 13, loss = 0.34229885\n",
      "Validation score: 0.885000\n",
      "Iteration 14, loss = 0.32618930\n",
      "Validation score: 0.891250\n",
      "Iteration 15, loss = 0.31167694\n",
      "Validation score: 0.895000\n",
      "Iteration 16, loss = 0.29825726\n",
      "Validation score: 0.902500\n",
      "Iteration 17, loss = 0.28720972\n",
      "Validation score: 0.903750\n",
      "Iteration 18, loss = 0.27520840\n",
      "Validation score: 0.906250\n",
      "Iteration 19, loss = 0.26487238\n",
      "Validation score: 0.908750\n",
      "Iteration 20, loss = 0.25586848\n",
      "Validation score: 0.903750\n",
      "Iteration 21, loss = 0.24612881\n",
      "Validation score: 0.915000\n",
      "Iteration 22, loss = 0.23744656\n",
      "Validation score: 0.913750\n",
      "Iteration 23, loss = 0.23064619\n",
      "Validation score: 0.920000\n",
      "Iteration 24, loss = 0.22357774\n",
      "Validation score: 0.911250\n",
      "Iteration 25, loss = 0.21654999\n",
      "Validation score: 0.922500\n",
      "Iteration 26, loss = 0.21024271\n",
      "Validation score: 0.921250\n",
      "Iteration 27, loss = 0.20398626\n",
      "Validation score: 0.917500\n",
      "Iteration 28, loss = 0.19940501\n",
      "Validation score: 0.926250\n",
      "Iteration 29, loss = 0.19347880\n",
      "Validation score: 0.925000\n",
      "Iteration 30, loss = 0.18751007\n",
      "Validation score: 0.931250\n",
      "Iteration 31, loss = 0.18305070\n",
      "Validation score: 0.922500\n",
      "Iteration 32, loss = 0.17832530\n",
      "Validation score: 0.928750\n",
      "Iteration 33, loss = 0.17468909\n",
      "Validation score: 0.928750\n",
      "Iteration 34, loss = 0.16960047\n",
      "Validation score: 0.927500\n",
      "Iteration 35, loss = 0.16668354\n",
      "Validation score: 0.932500\n",
      "Iteration 36, loss = 0.16314686\n",
      "Validation score: 0.937500\n",
      "Iteration 37, loss = 0.15903885\n",
      "Validation score: 0.937500\n",
      "Iteration 38, loss = 0.15551772\n",
      "Validation score: 0.927500\n",
      "Iteration 39, loss = 0.15236877\n",
      "Validation score: 0.933750\n",
      "Iteration 40, loss = 0.14905352\n",
      "Validation score: 0.936250\n",
      "Iteration 41, loss = 0.14653509\n",
      "Validation score: 0.933750\n",
      "Iteration 42, loss = 0.14303466\n",
      "Validation score: 0.937500\n",
      "Iteration 43, loss = 0.14034969\n",
      "Validation score: 0.937500\n",
      "Iteration 44, loss = 0.13795695\n",
      "Validation score: 0.935000\n",
      "Iteration 45, loss = 0.13522485\n",
      "Validation score: 0.935000\n",
      "Iteration 46, loss = 0.13268508\n",
      "Validation score: 0.938750\n",
      "Iteration 47, loss = 0.13029240\n",
      "Validation score: 0.935000\n",
      "Iteration 48, loss = 0.12752205\n",
      "Validation score: 0.933750\n",
      "Iteration 49, loss = 0.12569864\n",
      "Validation score: 0.936250\n",
      "Iteration 50, loss = 0.12293685\n",
      "Validation score: 0.936250\n",
      "Iteration 51, loss = 0.12047678\n",
      "Validation score: 0.937500\n",
      "Iteration 52, loss = 0.11854907\n",
      "Validation score: 0.938750\n",
      "Iteration 53, loss = 0.11663601\n",
      "Validation score: 0.938750\n",
      "Iteration 54, loss = 0.11453699\n",
      "Validation score: 0.941250\n",
      "Iteration 55, loss = 0.11209910\n",
      "Validation score: 0.942500\n",
      "Iteration 56, loss = 0.11047335\n",
      "Validation score: 0.948750\n",
      "Iteration 57, loss = 0.10854857\n",
      "Validation score: 0.941250\n",
      "Iteration 58, loss = 0.10686692\n",
      "Validation score: 0.947500\n",
      "Iteration 59, loss = 0.10510295\n",
      "Validation score: 0.945000\n",
      "Iteration 60, loss = 0.10354560\n",
      "Validation score: 0.945000\n",
      "Iteration 61, loss = 0.10146590\n",
      "Validation score: 0.945000\n",
      "Iteration 62, loss = 0.09976208\n",
      "Validation score: 0.943750\n",
      "Iteration 63, loss = 0.09884566\n",
      "Validation score: 0.946250\n",
      "Iteration 64, loss = 0.09762695\n",
      "Validation score: 0.943750\n",
      "Iteration 65, loss = 0.09604357\n",
      "Validation score: 0.948750\n",
      "Iteration 66, loss = 0.09378178\n",
      "Validation score: 0.946250\n",
      "Iteration 67, loss = 0.09257525\n",
      "Validation score: 0.948750\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=100, max_iter=1000,\n",
       "              random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=100, max_iter=1000,\n",
       "              random_state=42, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=100, max_iter=1000,\n",
       "              random_state=42, verbose=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_encoded_with_freq = MLPClassifier(hidden_layer_sizes=(100), random_state=42, max_iter=1000, verbose=True, early_stopping=True, validation_fraction=0.1)\n",
    "clf_encoded_with_freq.fit(encoded_with_freq_train_dataset, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.965042372881356,\n",
       "  'recall': 0.911,\n",
       "  'f1-score': 0.9372427983539094,\n",
       "  'support': 1000.0},\n",
       " '1': {'precision': 0.915719696969697,\n",
       "  'recall': 0.967,\n",
       "  'f1-score': 0.9406614785992218,\n",
       "  'support': 1000.0},\n",
       " 'accuracy': 0.939,\n",
       " 'macro avg': {'precision': 0.9403810349255265,\n",
       "  'recall': 0.9390000000000001,\n",
       "  'f1-score': 0.9389521384765656,\n",
       "  'support': 2000.0},\n",
       " 'weighted avg': {'precision': 0.9403810349255265,\n",
       "  'recall': 0.939,\n",
       "  'f1-score': 0.9389521384765656,\n",
       "  'support': 2000.0}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = clf_encoded_with_freq.predict(encoded_with_freq_test_dataset)\n",
    "classification_report(test_labels, test_preds, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.5,\n",
       "  'recall': 0.03711855927963982,\n",
       "  'f1-score': 0.06910682686038931,\n",
       "  'support': 9995.0},\n",
       " '1': {'precision': 0.500129849893523,\n",
       "  'recall': 0.9629,\n",
       "  'f1-score': 0.6583256418145147,\n",
       "  'support': 10000.0},\n",
       " 'accuracy': 0.5001250312578145,\n",
       " 'macro avg': {'precision': 0.5000649249467615,\n",
       "  'recall': 0.5000092796398199,\n",
       "  'f1-score': 0.363716234337452,\n",
       "  'support': 19995.0},\n",
       " 'weighted avg': {'precision': 0.500064941182057,\n",
       "  'recall': 0.5001250312578145,\n",
       "  'f1-score': 0.36378990510701364,\n",
       "  'support': 19995.0}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenge_preds = clf_encoded_with_freq.predict(encoded_with_freq_challenge_dataset)\n",
    "classification_report(challenge_labels, challenge_preds, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode as ASCII indices shifted to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_with_ascii_shifted_to_zero(seq):\n",
    "    seq = seq.upper()\n",
    "    assert len(seq) == SEQ_LENGTH, \"length of sequence must be {}\".format(SEQ_LENGTH)\n",
    "    encoding = [0]*SEQ_LENGTH\n",
    "    for i, char in enumerate(seq):\n",
    "        encoding[i] = ord(char) - ord('A')\n",
    "    return encoding\n",
    "\n",
    "encoded_with_ascii_shifted_to_zero_train_dataset = [encode_with_ascii_shifted_to_zero(seq) for seq in train_dataset]\n",
    "encoded_with_ascii_shifted_to_zero_test_dataset = [encode_with_ascii_shifted_to_zero(seq) for seq in test_dataset]\n",
    "encoded_with_ascii_shifted_to_zero_challenge_dataset = [encode_with_ascii_shifted_to_zero(seq) for seq in challenge_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.32416578\n",
      "Validation score: 0.528750\n",
      "Iteration 2, loss = 0.95393623\n",
      "Validation score: 0.522500\n",
      "Iteration 3, loss = 0.80655650\n",
      "Validation score: 0.538750\n",
      "Iteration 4, loss = 0.72736210\n",
      "Validation score: 0.580000\n",
      "Iteration 5, loss = 0.68438535\n",
      "Validation score: 0.601250\n",
      "Iteration 6, loss = 0.65335498\n",
      "Validation score: 0.631250\n",
      "Iteration 7, loss = 0.61706697\n",
      "Validation score: 0.675000\n",
      "Iteration 8, loss = 0.54369544\n",
      "Validation score: 0.778750\n",
      "Iteration 9, loss = 0.44295066\n",
      "Validation score: 0.841250\n",
      "Iteration 10, loss = 0.34327966\n",
      "Validation score: 0.896250\n",
      "Iteration 11, loss = 0.25384204\n",
      "Validation score: 0.928750\n",
      "Iteration 12, loss = 0.20276966\n",
      "Validation score: 0.940000\n",
      "Iteration 13, loss = 0.17127767\n",
      "Validation score: 0.957500\n",
      "Iteration 14, loss = 0.14769964\n",
      "Validation score: 0.958750\n",
      "Iteration 15, loss = 0.12880724\n",
      "Validation score: 0.967500\n",
      "Iteration 16, loss = 0.11204375\n",
      "Validation score: 0.970000\n",
      "Iteration 17, loss = 0.09919714\n",
      "Validation score: 0.976250\n",
      "Iteration 18, loss = 0.08845136\n",
      "Validation score: 0.977500\n",
      "Iteration 19, loss = 0.07733877\n",
      "Validation score: 0.976250\n",
      "Iteration 20, loss = 0.06872932\n",
      "Validation score: 0.976250\n",
      "Iteration 21, loss = 0.06156390\n",
      "Validation score: 0.978750\n",
      "Iteration 22, loss = 0.05507805\n",
      "Validation score: 0.980000\n",
      "Iteration 23, loss = 0.04937523\n",
      "Validation score: 0.980000\n",
      "Iteration 24, loss = 0.04475757\n",
      "Validation score: 0.982500\n",
      "Iteration 25, loss = 0.04122604\n",
      "Validation score: 0.983750\n",
      "Iteration 26, loss = 0.03774274\n",
      "Validation score: 0.986250\n",
      "Iteration 27, loss = 0.03481020\n",
      "Validation score: 0.986250\n",
      "Iteration 28, loss = 0.03191881\n",
      "Validation score: 0.987500\n",
      "Iteration 29, loss = 0.02950315\n",
      "Validation score: 0.987500\n",
      "Iteration 30, loss = 0.02753193\n",
      "Validation score: 0.987500\n",
      "Iteration 31, loss = 0.02561254\n",
      "Validation score: 0.988750\n",
      "Iteration 32, loss = 0.02402573\n",
      "Validation score: 0.988750\n",
      "Iteration 33, loss = 0.02220736\n",
      "Validation score: 0.990000\n",
      "Iteration 34, loss = 0.02114905\n",
      "Validation score: 0.991250\n",
      "Iteration 35, loss = 0.01969159\n",
      "Validation score: 0.991250\n",
      "Iteration 36, loss = 0.01893516\n",
      "Validation score: 0.991250\n",
      "Iteration 37, loss = 0.01787102\n",
      "Validation score: 0.991250\n",
      "Iteration 38, loss = 0.01700939\n",
      "Validation score: 0.991250\n",
      "Iteration 39, loss = 0.01654293\n",
      "Validation score: 0.991250\n",
      "Iteration 40, loss = 0.01585946\n",
      "Validation score: 0.991250\n",
      "Iteration 41, loss = 0.01562485\n",
      "Validation score: 0.991250\n",
      "Iteration 42, loss = 0.01488444\n",
      "Validation score: 0.991250\n",
      "Iteration 43, loss = 0.01437309\n",
      "Validation score: 0.992500\n",
      "Iteration 44, loss = 0.01385809\n",
      "Validation score: 0.992500\n",
      "Iteration 45, loss = 0.01332104\n",
      "Validation score: 0.992500\n",
      "Iteration 46, loss = 0.01270764\n",
      "Validation score: 0.992500\n",
      "Iteration 47, loss = 0.01260795\n",
      "Validation score: 0.995000\n",
      "Iteration 48, loss = 0.01214875\n",
      "Validation score: 0.992500\n",
      "Iteration 49, loss = 0.01190957\n",
      "Validation score: 0.995000\n",
      "Iteration 50, loss = 0.01123037\n",
      "Validation score: 0.995000\n",
      "Iteration 51, loss = 0.01093884\n",
      "Validation score: 0.995000\n",
      "Iteration 52, loss = 0.01075071\n",
      "Validation score: 0.993750\n",
      "Iteration 53, loss = 0.01029815\n",
      "Validation score: 0.995000\n",
      "Iteration 54, loss = 0.01029256\n",
      "Validation score: 0.995000\n",
      "Iteration 55, loss = 0.00979423\n",
      "Validation score: 0.995000\n",
      "Iteration 56, loss = 0.00947433\n",
      "Validation score: 0.993750\n",
      "Iteration 57, loss = 0.00961529\n",
      "Validation score: 0.993750\n",
      "Iteration 58, loss = 0.00914576\n",
      "Validation score: 0.995000\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(9, 9), max_iter=1000,\n",
       "              random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(9, 9), max_iter=1000,\n",
       "              random_state=42, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=(9, 9), max_iter=1000,\n",
       "              random_state=42, verbose=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_encoded_with_ascii_shifted_to_zero = MLPClassifier(hidden_layer_sizes=(9,9), random_state=42, max_iter=1000, verbose=True, early_stopping=True, validation_fraction=0.1)\n",
    "mlp_encoded_with_ascii_shifted_to_zero.fit(encoded_with_ascii_shifted_to_zero_train_dataset, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 9), (9, 9))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print MLP weights\n",
    "mlp_encoded_with_ascii_shifted_to_zero.coefs_[0].shape, mlp_encoded_with_ascii_shifted_to_zero.coefs_[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 1.0,\n",
       "  'recall': 0.993,\n",
       "  'f1-score': 0.9964877069744105,\n",
       "  'support': 1000.0},\n",
       " '1': {'precision': 0.9930486593843099,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9965122072745392,\n",
       "  'support': 1000.0},\n",
       " 'accuracy': 0.9965,\n",
       " 'macro avg': {'precision': 0.9965243296921549,\n",
       "  'recall': 0.9964999999999999,\n",
       "  'f1-score': 0.9964999571244748,\n",
       "  'support': 2000.0},\n",
       " 'weighted avg': {'precision': 0.9965243296921549,\n",
       "  'recall': 0.9965,\n",
       "  'f1-score': 0.9964999571244748,\n",
       "  'support': 2000.0}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = mlp_encoded_with_ascii_shifted_to_zero.predict(encoded_with_ascii_shifted_to_zero_test_dataset)\n",
    "classification_report(test_labels, test_preds, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 1.0,\n",
       "  'recall': 0.8367183591795898,\n",
       "  'f1-score': 0.9111014271707157,\n",
       "  'support': 9995.0},\n",
       " '1': {'precision': 0.859697386519945,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9245562130177514,\n",
       "  'support': 10000.0},\n",
       " 'accuracy': 0.9183795948987247,\n",
       " 'macro avg': {'precision': 0.9298486932599725,\n",
       "  'recall': 0.918359179589795,\n",
       "  'f1-score': 0.9178288200942335,\n",
       "  'support': 19995.0},\n",
       " 'weighted avg': {'precision': 0.9298311510477344,\n",
       "  'recall': 0.9183795948987247,\n",
       "  'f1-score': 0.9178305023630317,\n",
       "  'support': 19995.0}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenge_preds = mlp_encoded_with_ascii_shifted_to_zero.predict(encoded_with_ascii_shifted_to_zero_challenge_dataset)\n",
    "classification_report(challenge_labels, challenge_preds, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
